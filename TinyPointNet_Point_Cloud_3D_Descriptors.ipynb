{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pfA1XNq2RnI"
      },
      "source": [
        "# 3D Data Processing\n",
        "\n",
        "---\n",
        "A.A. 2024 - Wanmeng Li, Daniel Fusaro\n",
        "---\n",
        "\n",
        "\n",
        "## Lab - PointNet: Point Cloud 3D Descriptors\n",
        "\n",
        "original paper -\n",
        "[PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation](https://web.stanford.edu/~rqi/pointnet/)\n",
        "\n",
        "dataset link: https://drive.google.com/drive/folders/1IweJGcOeOZN3wY79i2jFt3JE1bd7G51Z?usp=share_link\n",
        "\n",
        "SHOT descriptions: [lecture](https://stem.elearning.unipd.it/pluginfile.php/517107/mod_resource/content/25/Slide_3DP_13_3D%20Local%20Descriptors.pdf)\n",
        "\n",
        "To add a link to the dataset in your Google Drive main folder, you need to:\n",
        "\n",
        " - Click on the link\n",
        " - Right click on \"dataset\"\n",
        " - Click Add shortcut to Drive\n",
        "\n",
        "When you will mount your drive folder in Colab you will find this folder without the need of re-uploading it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hc7eaUqkcmAz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import copy\n",
        "import os\n",
        "import glob\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial.transform import Rotation as R\n",
        "\n",
        "# pyTorch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# a nice training progress bar\n",
        "from tqdm import tqdm, trange"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qSyKEXWMmI2Y",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8885880a-f77f-4a04-c92a-53e0df30468b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting open3d\n",
            "  Downloading open3d-0.18.0-cp310-cp310-manylinux_2_27_x86_64.whl (399.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.7/399.7 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.25.2)\n",
            "Collecting dash>=2.6.0 (from open3d)\n",
            "  Downloading dash-2.17.0-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.0.3)\n",
            "Requirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (5.10.4)\n",
            "Collecting configargparse (from open3d)\n",
            "  Downloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n",
            "Collecting ipywidgets>=8.0.4 (from open3d)\n",
            "  Downloading ipywidgets-8.1.3-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict (from open3d)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: pillow>=9.3.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (9.4.0)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (2.0.3)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from open3d) (6.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from open3d) (4.66.4)\n",
            "Collecting pyquaternion (from open3d)\n",
            "  Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.2.5)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (5.15.0)\n",
            "Collecting dash-html-components==2.0.0 (from dash>=2.6.0->open3d)\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Collecting dash-core-components==2.0.0 (from dash>=2.6.0->open3d)\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting dash-table==5.0.0 (from dash>=2.6.0->open3d)\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (7.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (4.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.31.0)\n",
            "Collecting retrying (from dash>=2.6.0->open3d)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (67.7.2)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.0.4->open3d)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.11 (from ipywidgets>=8.0.4->open3d)\n",
            "  Downloading widgetsnbextension-4.0.11-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyterlab-widgets~=3.0.11 (from ipywidgets>=8.0.4->open3d)\n",
            "  Downloading jupyterlab_widgets-3.0.11-py3-none-any.whl (214 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.4/214.4 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (2.8.2)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (4.19.2)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (5.7.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=2.2.3->open3d) (2.1.5)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (8.1.7)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.18.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.2.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (8.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3->open3d) (1.16.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (2024.2.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\n",
            "Installing collected packages: dash-table, dash-html-components, dash-core-components, addict, widgetsnbextension, retrying, pyquaternion, jupyterlab-widgets, jedi, configargparse, comm, ipywidgets, dash, open3d\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.6\n",
            "    Uninstalling widgetsnbextension-3.6.6:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.6\n",
            "  Attempting uninstall: jupyterlab-widgets\n",
            "    Found existing installation: jupyterlab_widgets 3.0.10\n",
            "    Uninstalling jupyterlab_widgets-3.0.10:\n",
            "      Successfully uninstalled jupyterlab_widgets-3.0.10\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed addict-2.4.0 comm-0.2.2 configargparse-1.7 dash-2.17.0 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 ipywidgets-8.1.3 jedi-0.19.1 jupyterlab-widgets-3.0.11 open3d-0.18.0 pyquaternion-0.9.9 retrying-1.3.4 widgetsnbextension-4.0.11\n"
          ]
        }
      ],
      "source": [
        "running_on_colab = True\n",
        "\n",
        "if running_on_colab:\n",
        "    # useful for visualization\n",
        "    ## note: it's not necessary to restart the notebook environment after installation\n",
        "    !pip install open3d\n",
        "\n",
        "    import plotly.graph_objects as go\n",
        "\n",
        "# visualization\n",
        "import open3d as o3d\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuR9palyGqil"
      },
      "source": [
        "# Connect and mount your Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wjgl1d34-CWw",
        "outputId": "f7c044c5-1205-4360-b84d-c7386c6885b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "if running_on_colab:\n",
        "    from google.colab import drive\n",
        "    drive_path = '/content/drive'\n",
        "    drive.mount(drive_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hK1CJSoJGvi7"
      },
      "source": [
        "# General Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1LWQSdhp3CiT",
        "tags": []
      },
      "outputs": [],
      "source": [
        "if running_on_colab:\n",
        "    dataset_path_train = os.path.join(drive_path, \"MyDrive\", \"3D_dp_dataset\", \"3dshapes\", \"train\")\n",
        "    dataset_path_valid = os.path.join(drive_path, \"MyDrive\", \"3D_dp_dataset\", \"3dshapes\", \"valid\")\n",
        "    dataset_path_test = os.path.join(drive_path,  \"MyDrive\", \"3D_dp_dataset\", \"3dshapes\", \"test\")\n",
        "else:\n",
        "    dataset_path_train = os.path.join(\"datasets\", \"train\")\n",
        "    dataset_path_valid = os.path.join(\"datasets\", \"valid\")\n",
        "    dataset_path_test = os.path.join(\"datasets\", \"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWcO-JoNzH17",
        "tags": []
      },
      "source": [
        "# Visualization Example\n",
        "In order to visualize colored point clouds we make use of the Python package *Open3D*.\n",
        "\n",
        "Unfortunately, the original doesn't run on Colab.\n",
        "So, we replace the drawing function with a custom one (*draw_geometries*) that allows for rendering here on Colab.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9ceZKVwpfdG0",
        "tags": []
      },
      "outputs": [],
      "source": [
        "if running_on_colab:\n",
        "    def draw_geometries(geometries):\n",
        "        graph_objects = []\n",
        "\n",
        "        for geometry in geometries:\n",
        "            geometry_type = geometry.get_geometry_type()\n",
        "\n",
        "            if geometry_type == o3d.geometry.Geometry.Type.PointCloud:\n",
        "                points = np.asarray(geometry.points)\n",
        "                colors = None\n",
        "                if geometry.has_colors():\n",
        "                    colors = np.asarray(geometry.colors)\n",
        "                elif geometry.has_normals():\n",
        "                    colors = (0.5, 0.5, 0.5) + np.asarray(geometry.normals) * 0.5\n",
        "                else:\n",
        "                    geometry.paint_uniform_color((1.0, 0.0, 0.0))\n",
        "                    colors = np.asarray(geometry.colors)\n",
        "\n",
        "                scatter_3d = go.Scatter3d(x=points[:,0], y=points[:,1], z=points[:,2], mode='markers', marker=dict(size=1, color=colors))\n",
        "                graph_objects.append(scatter_3d)\n",
        "\n",
        "            if geometry_type == o3d.geometry.Geometry.Type.TriangleMesh:\n",
        "                triangles = np.asarray(geometry.triangles)\n",
        "                vertices = np.asarray(geometry.vertices)\n",
        "                colors = None\n",
        "                if geometry.has_triangle_normals():\n",
        "                    colors = (0.5, 0.5, 0.5) + np.asarray(geometry.triangle_normals) * 0.5\n",
        "                    colors = tuple(map(tuple, colors))\n",
        "                else:\n",
        "                    colors = (1.0, 0.0, 0.0)\n",
        "\n",
        "                mesh_3d = go.Mesh3d(x=vertices[:,0], y=vertices[:,1], z=vertices[:,2], i=triangles[:,0], j=triangles[:,1], k=triangles[:,2], facecolor=colors, opacity=0.50)\n",
        "                graph_objects.append(mesh_3d)\n",
        "\n",
        "        fig = go.Figure(\n",
        "            data=graph_objects,\n",
        "            layout=dict(\n",
        "                scene=dict(\n",
        "                    xaxis=dict(visible=False),\n",
        "                    yaxis=dict(visible=False),\n",
        "                    zaxis=dict(visible=False),\n",
        "                    aspectmode='data'\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "        fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ywtBnEqw10u3",
        "tags": []
      },
      "outputs": [],
      "source": [
        "if running_on_colab:\n",
        "    o3d.visualization.draw_geometries = draw_geometries\n",
        "\n",
        "anchor_color   = [0, 0, 1.0] # blue\n",
        "positive_color = [0, 1.0, 0] # green\n",
        "negative_color = [1.0, 0, 0] # red\n",
        "p_colors = [anchor_color, positive_color, negative_color]\n",
        "\n",
        "def visualize( pointcloud:np.array =None,\n",
        "               anchor    :np.array =None,\n",
        "               positive  :np.array =None,\n",
        "               negative  :np.array =None,\n",
        "               radius    :np.array =None,\n",
        "               rot_mat   :np.array =None):\n",
        "    \"\"\"\n",
        "    INPUT\n",
        "      pointcloud : numpy array of 3D points\n",
        "      anchor     : anchor point\n",
        "      positive   :\n",
        "      negative   :\n",
        "    \"\"\"\n",
        "    geoms = []\n",
        "    if pointcloud is not None:\n",
        "        pcd = o3d.geometry.PointCloud()\n",
        "        pcd.points = o3d.utility.Vector3dVector(pointcloud)\n",
        "        pcd.paint_uniform_color([0.6, 0.6, 0.6])\n",
        "        if rot_mat is not None:\n",
        "            pcd.rotate(rot_mat, center=(0, 0, 0))\n",
        "        geoms.append(pcd)\n",
        "    for point, color in zip([anchor, positive, negative], p_colors):\n",
        "        if point is not None:\n",
        "            assert radius is not None\n",
        "            sphere = o3d.geometry.TriangleMesh.create_sphere(radius=radius, resolution=20)\n",
        "            sphere.translate(point)\n",
        "            sphere.paint_uniform_color(color)\n",
        "            geoms.append(sphere)\n",
        "    # visualize the colored point cloud\n",
        "    o3d.visualization.draw_geometries(geoms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLp113kezNBG",
        "tags": []
      },
      "source": [
        "# PointCloud Dataset\n",
        "\n",
        "`torch.utils.data.Dataset` is an abstract class representing a dataset. Your custom dataset should inherit `Dataset` and override the following methods:\n",
        "\n",
        "* `__init__` to initialize your dataset. For example, if your dataset fits in memory, you can load the entire dataset in a list, or you can just store the list of dataset files.\n",
        "* `__len__` so that len(dataset) returns the size of the dataset.\n",
        "* `__getitem__` to support indexing such that `dataset[i]` can be used to get  the i-th sample\n",
        "\n",
        "Therefore, the structure of the class is:\n",
        "\n",
        "```\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, init_parameters):\n",
        "        self.param1 = param1\n",
        "        [...]\n",
        "\n",
        "    def __len__(self):\n",
        "        [...]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        [...]\n",
        "\n",
        "        return sample[idx]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PointCloudData(Dataset):\n",
        "    def __init__(self,\n",
        "                dataset_path: str,\n",
        "                samples_per_epoch: int,\n",
        "                points_to_sample:int = 200000,\n",
        "                radius:float =0.02,\n",
        "                min_dist=1.5e-2,\n",
        "                N = 750,\n",
        "                noise_mean=0,\n",
        "                noise_variance = 6e-5,\n",
        "                is_test_set=False):\n",
        "        \"\"\"\n",
        "          INPUT\n",
        "              dataset_path: path to the dataset folder\n",
        "              transform   : transform function to apply to point cloud\n",
        "        \"\"\"\n",
        "\n",
        "        self.radius = radius\n",
        "        self.min_dist = min_dist\n",
        "        self.N = N\n",
        "        self.samples_per_epoch = samples_per_epoch\n",
        "        self.points_to_sample = points_to_sample\n",
        "        self.noise_mean = noise_mean\n",
        "        self.noise_variance = noise_variance\n",
        "        self.is_test_set = is_test_set\n",
        "\n",
        "        # _n means noised version\n",
        "        self.mesh = []\n",
        "        self.pcds, self.pcds_n = [], []\n",
        "        self.KDtrees, self.KDtrees_n = [], []\n",
        "\n",
        "        ## if it's the test set, pre-define a random rotation matrix\n",
        "        if self.is_test_set:\n",
        "            self.common_rot_mat = self.get_xyz_random_rotation()\n",
        "\n",
        "        for file in glob.glob(dataset_path + \"/*.ply\"):\n",
        "            print(\"parsing file\", file)\n",
        "            mesh = o3d.io.read_triangle_mesh(file)\n",
        "            pcd = mesh.sample_points_uniformly(self.points_to_sample)\n",
        "            if self.is_test_set:\n",
        "                pcd.rotate(self.common_rot_mat.as_matrix(), center=(0, 0, 0))\n",
        "            pcd_tree = o3d.geometry.KDTreeFlann(pcd)\n",
        "\n",
        "            pcd_n = self.apply_noise(mesh.sample_points_uniformly(self.points_to_sample), self.noise_mean, self.noise_variance)\n",
        "            if self.is_test_set:\n",
        "                pcd_n.rotate(self.common_rot_mat.as_matrix(), center=(0, 0, 0))\n",
        "            pcd_n_tree = o3d.geometry.KDTreeFlann(pcd_n)\n",
        "\n",
        "            self.mesh.append(mesh)\n",
        "\n",
        "            self.pcds.append(np.asarray(pcd.points))\n",
        "            self.pcds_n.append(np.asarray(pcd_n.points))\n",
        "\n",
        "            self.KDtrees.append(pcd_tree)\n",
        "            self.KDtrees_n.append(pcd_n_tree)\n",
        "\n",
        "            if len(self.mesh) == 0:\n",
        "              raise ValueError(\"No point cloud data loaded. Please check the dataset path and ensure it contains .ply files.\")\n",
        "\n",
        "\n",
        "    # function to apply noise\n",
        "    def apply_noise(self, pcd, mu, sigma):\n",
        "        noisy_pcd = copy.deepcopy(pcd)\n",
        "        points = np.asarray(noisy_pcd.points)\n",
        "        points += np.random.normal(mu, sigma, size=points.shape)\n",
        "        noisy_pcd.points = o3d.utility.Vector3dVector(points)\n",
        "        return noisy_pcd\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.samples_per_epoch\n",
        "\n",
        "    def get_xyz_random_rotation(self):\n",
        "        random_rotation_on_xyz_axis = np.random.rand(3) * 2 * np.pi\n",
        "        return R.from_euler('xyz', random_rotation_on_xyz_axis, degrees=False)\n",
        "\n",
        "    def get_point_cloud_center(self, pc_points):\n",
        "        return pc_points.mean(axis=0)\n",
        "\n",
        "    def apply_rotation(self, point, rot_mat, pcd_center):\n",
        "        return np.dot(point.reshape(1, 3), rot_mat.as_matrix().T)[0, :]\n",
        "\n",
        "    def apply_rotation_pc(slef, points, rot_mat, pcd_center):\n",
        "        return np.dot(points, rot_mat.as_matrix().T)\n",
        "\n",
        "    def bufferize_pointcloud(self, points, N):\n",
        "        pc = np.zeros((self.N, 3), dtype=np.float32)\n",
        "        pc[:min(self.N, points.shape[0]), :] = points[:min(self.N, points.shape[0]), :]\n",
        "        return pc\n",
        "\n",
        "    def sample_anchor_point(self, pcd_points, pcd_tree):\n",
        "        ############# START ###########\n",
        "        ######### COMPLETE HERE #######\n",
        "        anchor_index = np.random.randint(0, len(pcd_points))\n",
        "        anchor_pt = pcd_points[anchor_index]\n",
        "\n",
        "        _, anchor_neighborhood_idxs, _ = pcd_tree.search_radius_vector_3d(anchor_pt, self.radius)\n",
        "\n",
        "        ############# END #############\n",
        "        return anchor_pt, anchor_neighborhood_idxs\n",
        "\n",
        "    def sample_positive_point(self, pcd_n_points, pcd_n_tree, anchor_pt):\n",
        "        _, noisy_anchor_nn_idx, _ = pcd_n_tree.search_knn_vector_3d(anchor_pt, 1)\n",
        "\n",
        "        ############# START ###########\n",
        "        ######### COMPLETE HERE #######\n",
        "        # pcd_n_points[noisy_anchor_nn_idx]\n",
        "        pos_pt = pcd_n_points[noisy_anchor_nn_idx]\n",
        "        _, noisy_positive_neighborhood_idxs, _ = pcd_n_tree.search_radius_vector_3d(pos_pt, self.radius)\n",
        "\n",
        "\n",
        "        ############# END #############\n",
        "\n",
        "        return pos_pt, noisy_positive_neighborhood_idxs\n",
        "\n",
        "    def sample_negative_point(self, pcd_n_points, pcd_n_tree, anchor_pt):\n",
        "        ############# START ###########\n",
        "        ######### COMPLETE HERE #######\n",
        "            # Continue searching until a valid negative point is found\n",
        "        while True:\n",
        "            neg_index = np.random.randint(0, len(pcd_n_points))\n",
        "            neg_pt = pcd_n_points[neg_index]\n",
        "\n",
        "            # Ensure the negative point is far enough from the anchor point\n",
        "            if np.linalg.norm(neg_pt - anchor_pt) > self.min_dist:\n",
        "                _, noisy_negative_neighborhood_idxs, _ = pcd_n_tree.search_radius_vector_3d(neg_pt, self.radius)\n",
        "                return neg_pt, noisy_negative_neighborhood_idxs\n",
        "\n",
        "        ############# END #############\n",
        "\n",
        "    def get_sampled_pointcloud(self, mesh_idx, N):\n",
        "        idxs = np.arange(0, self.pcds[mesh_idx].shape[0], 1)\n",
        "        np.random.shuffle(idxs)\n",
        "        pcd = o3d.geometry.PointCloud()\n",
        "        pcd.points = o3d.utility.Vector3dVector(self.pcds[mesh_idx][idxs[:N]])\n",
        "        return pcd\n",
        "\n",
        "    def generate_test_set(self, mesh_idx, N=500):\n",
        "\n",
        "        self.test_points = self.pcds[mesh_idx]\n",
        "\n",
        "        ## sample test points randomly\n",
        "        idxs = np.arange(0, self.test_points.shape[0], 1)\n",
        "        np.random.shuffle(idxs)\n",
        "        self.test_points_sampled = self.test_points[idxs[:N]]\n",
        "\n",
        "        # ## as a bonus study: you can sample keypoints from the point cloud\n",
        "        # ## using open3d and analyze the results. Keypoints are inherently easier.\n",
        "        # pcd = o3d.geometry.PointCloud()\n",
        "        # pcd.points = o3d.utility.Vector3dVector(self.pcds[mesh_idx])\n",
        "        # keypoints = o3d.geometry.keypoint.compute_iss_keypoints(pcd,\n",
        "        #                                                 salient_radius=0.005,\n",
        "        #                                                 non_max_radius=0.005,\n",
        "        #                                                 gamma_21=0.4,\n",
        "        #                                                 gamma_32=0.5)\n",
        "        # self.test_points_sampled = np.random.permutation(np.asarray(keypoints.points))\n",
        "\n",
        "        self.test_tree = self.KDtrees[mesh_idx]\n",
        "\n",
        "    def generate_noisy_test_set(self, mesh_idx):\n",
        "        self.test_points_n = self.pcds_n[mesh_idx]\n",
        "        self.test_tree_n = self.KDtrees_n[mesh_idx]\n",
        "\n",
        "        test_points_sampled_n = []\n",
        "        for i in tqdm(range(self.test_points_sampled.shape[0])):\n",
        "            _, gt_nn_idx, _ = self.test_tree_n.search_knn_vector_3d(self.test_points_sampled[i], 1)\n",
        "            gt_nearest_point = self.test_points_n[gt_nn_idx].squeeze()\n",
        "            test_points_sampled_n.append(gt_nearest_point)\n",
        "\n",
        "        self.test_points_sampled_n = np.asarray(test_points_sampled_n)\n",
        "\n",
        "    def compute_descriptors(self, tinypointnet, noisy=False):\n",
        "        tinypointnet.eval()\n",
        "\n",
        "        if noisy:\n",
        "            queries = self.test_points_sampled_n\n",
        "            tree    = self.test_tree_n\n",
        "            points  = self.test_points_n\n",
        "        else:\n",
        "            queries = self.test_points_sampled\n",
        "            tree    = self.test_tree\n",
        "            points  = self.test_points\n",
        "        tot_queries = queries.shape[0]\n",
        "\n",
        "        descriptors = np.zeros((tot_queries, 256), dtype=np.float32)\n",
        "        for i in tqdm(range(tot_queries)):\n",
        "            pt = queries[i]\n",
        "\n",
        "            ## find neighborhood of points\n",
        "            _, idx, _ = tree.search_radius_vector_3d(pt, self.radius)\n",
        "            point_set = points[idx]\n",
        "\n",
        "            ## normalize the points\n",
        "            point_set = (point_set - pt)\n",
        "\n",
        "            pc = np.zeros((self.N, 3), dtype=np.float32)\n",
        "            pc[:min(self.N, point_set.shape[0]), :] = point_set[:min(self.N, point_set.shape[0]), :]\n",
        "\n",
        "            # transform\n",
        "            anchor  = torch.from_numpy(pc).unsqueeze(0).float().transpose(1,2).to(device)\n",
        "            descriptors[i, :] = tinypointnet(anchor)[0, :, 0].cpu().detach().numpy()\n",
        "        return descriptors\n",
        "\n",
        "    def __getitem__(self, _):\n",
        "        mesh_idx = np.random.randint(0, len(self.mesh))\n",
        "\n",
        "        pcd_points = self.pcds[mesh_idx]        ## anchor will be drawn from this\n",
        "        pcd_n_points = self.pcds_n[mesh_idx]    ## positive and negative will be drawn from this\n",
        "\n",
        "        # ANCHOR: select a random anchor point\n",
        "        anchor_pt, anchor_neighborhood_idxs = self.sample_anchor_point(pcd_points, self.KDtrees[mesh_idx])\n",
        "\n",
        "        # POSITIVE: find corresponding point in the noisy point cloud\n",
        "        pos_pt, noisy_positive_neighborhood_idxs = self.sample_positive_point(pcd_n_points, self.KDtrees_n[mesh_idx], anchor_pt)\n",
        "\n",
        "        # NEGATIVE: find far point (at least at distance min_dist)\n",
        "        neg_pt, noisy_negative_neighborhood_idxs = self.sample_negative_point(pcd_n_points, self.KDtrees_n[mesh_idx], anchor_pt)\n",
        "        if neg_pt is None: ## it should never fail, but if it fails: restart experiment\n",
        "            quit(\"FAIL: restart experiment\")\n",
        "\n",
        "\n",
        "        # get points\n",
        "        point_set_anchor   = pcd_points[anchor_neighborhood_idxs]\n",
        "        point_set_positive = pcd_n_points[noisy_positive_neighborhood_idxs]\n",
        "        point_set_negative = pcd_n_points[noisy_negative_neighborhood_idxs]\n",
        "\n",
        "        if not self.is_test_set:\n",
        "            # generate a random rotation\n",
        "            rot_mat = self.get_xyz_random_rotation()\n",
        "\n",
        "            # apply the random rotation to point cloud and points\n",
        "            pcd_points_center = self.get_point_cloud_center(pcd_points)\n",
        "            pcd_n_points_center = self.get_point_cloud_center(pcd_n_points)\n",
        "            anchor_pt = self.apply_rotation(anchor_pt, rot_mat, pcd_points_center)\n",
        "            pos_pt    = self.apply_rotation(pos_pt, rot_mat, pcd_n_points_center)\n",
        "            neg_pt    = self.apply_rotation(neg_pt, rot_mat, pcd_n_points_center)\n",
        "            point_set_anchor   = self.apply_rotation_pc(point_set_anchor, rot_mat, pcd_points_center)\n",
        "            point_set_positive = self.apply_rotation_pc(point_set_positive, rot_mat, pcd_n_points_center)\n",
        "            point_set_negative = self.apply_rotation_pc(point_set_negative, rot_mat, pcd_n_points_center)\n",
        "        else:\n",
        "            rot_mat = self.common_rot_mat\n",
        "\n",
        "        # center points around their centroid\n",
        "        point_set_anchor   = (point_set_anchor - anchor_pt)\n",
        "        point_set_positive = (point_set_positive - pos_pt)\n",
        "        point_set_negative = (point_set_negative - neg_pt)\n",
        "\n",
        "        # copy points coordinates to a fixed dimension np.array\n",
        "        point_set_anchor   = self.bufferize_pointcloud(point_set_anchor  , self.N)\n",
        "        point_set_positive = self.bufferize_pointcloud(point_set_positive, self.N)\n",
        "        point_set_negative = self.bufferize_pointcloud(point_set_negative, self.N)\n",
        "\n",
        "        # transform from numpy to torch.Tensor\n",
        "        point_set_anchor    = torch.from_numpy(point_set_anchor)\n",
        "        point_set_positive  = torch.from_numpy(point_set_positive)\n",
        "        point_set_negative  = torch.from_numpy(point_set_negative)\n",
        "\n",
        "        return mesh_idx, point_set_anchor, point_set_positive, point_set_negative, anchor_pt, pos_pt, neg_pt, rot_mat.as_matrix()"
      ],
      "metadata": {
        "id": "FzSo25WFiFB4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABoR7ciUCrq_",
        "tags": []
      },
      "source": [
        "\n",
        "# Dataset Creation\n",
        "\n",
        "Now we can instantiate our training and test dataset objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mq_sC59txbQF",
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_ds  = PointCloudData(dataset_path_train, samples_per_epoch=500)\n",
        "valid_ds  = PointCloudData(dataset_path_valid, samples_per_epoch=500)\n",
        "test_ds   = PointCloudData(dataset_path_test,  samples_per_epoch=500, is_test_set=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC5c_b1quNFT"
      },
      "source": [
        "Creating a `Dataset` class may seem unnecessary for the most basic problems. But it really helps when the dataset and the training procedure start to get more complex.\n",
        "\n",
        "One of the most useful benefit of defining a `Dataset` class is the possiblity to use the PyTorch `Dataloader` module.\n",
        "\n",
        "By operating on the dataset directly, we are losing out on a lot of features by using a simple for loop to iterate over the data. In particular, we are missing out on:\n",
        "\n",
        "* Batching the data\n",
        "* Shuffling the data\n",
        "* Load the data in parallel using multiprocessing workers.\n",
        "\n",
        "`torch.utils.data.DataLoader` is an iterator which provides all these features. Parameters used below should be clear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lX2pNbMhxm0N",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# warning: batch_size needs to be at least 2\n",
        "train_loader  = DataLoader( dataset=train_ds,  batch_size=50, shuffle=True  )\n",
        "valid_loader  = DataLoader( dataset=valid_ds,  batch_size=50, shuffle=False )\n",
        "test_loader   = DataLoader( dataset=test_ds,   batch_size=20, shuffle=False )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kyi7gRrrVvfa",
        "outputId": "6b276534-10c4-43c8-9b55-b078d3ca3055"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IzNMJKK10u4",
        "tags": []
      },
      "source": [
        "# Visualize some data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "yPswsKFl10u4",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "571081cc-7adc-482c-fcaa-a2a3c7b7e076"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "high <= 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-1e84cd3b8834>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmesh_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrot_mat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmesh_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     visualize(ds.pcds[idx],\n",
            "\u001b[0;32m<ipython-input-8-4f290661f0f2>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, _)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mmesh_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mpcd_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpcds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmesh_idx\u001b[0m\u001b[0;34m]\u001b[0m        \u001b[0;31m## anchor will be drawn from this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_bounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: high <= 0"
          ]
        }
      ],
      "source": [
        "ds = train_ds\n",
        "\n",
        "for (mesh_idx, _, _, _, anchor, positive, negative, rot_mat) in ds:\n",
        "    idx = mesh_idx\n",
        "    visualize(ds.pcds[idx],\n",
        "              anchor = anchor,\n",
        "              positive = positive,\n",
        "              negative = negative,\n",
        "              radius=ds.radius,\n",
        "              rot_mat=rot_mat)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPtnhEyuy9ks",
        "tags": []
      },
      "source": [
        "# Network Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HjszmGzub9M"
      },
      "source": [
        "## Network Base Module\n",
        "\n",
        "A network is defined by extending the *torch.nn.module* class. The basic structure is:\n",
        "\n",
        "```\n",
        "class Net(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_parameters):\n",
        "        super().__init__() # This executes the parent __init__ method\n",
        "        [...]\n",
        "\n",
        "    def forward(self, x, optional_parameters):\n",
        "        [...]\n",
        "        return out # return the output of the network\n",
        "```\n",
        "\n",
        "You need to define two methods:\n",
        "*   **\\_\\_init\\_\\_**: The constructor method. This is exectuted when the object is initialized (no need to call it explicitly). Here you have to instantiate all the network's parameters. PyTorch provides utility functions to easily initialize most of the commonly used deep learning layers.\n",
        "*   **forward**: Here you define the forward pass of the network, from the input *x* to the output (the method must return the network output). You just need to define the forward part, the back-propagation is automatically tracked by the framework!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "HpMGFh5_bj5I",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# Multi Layer Perceptron\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super().__init__()\n",
        "        self.input_size   = input_size\n",
        "        self.output_size  = output_size\n",
        "        self.conv  = nn.Conv1d(self.input_size, self.output_size, 1)\n",
        "        self.bn    = nn.BatchNorm1d(self.output_size)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return F.relu(self.bn(self.conv(input)))\n",
        "\n",
        "# Fully Connected with Batch Normalization\n",
        "class FC_BN(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super().__init__()\n",
        "        self.input_size   = input_size\n",
        "        self.output_size  = output_size\n",
        "        self.lin  = nn.Linear(self.input_size, self.output_size)\n",
        "        self.bn    = nn.BatchNorm1d(self.output_size)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return F.relu(self.bn(self.lin(input)))\n",
        "\n",
        "class TNet(nn.Module):\n",
        "    def __init__(self, k=3):\n",
        "        super().__init__()\n",
        "        self.k=k\n",
        "\n",
        "        self.mlp1 = MLP(self.k, 64)\n",
        "        self.mlp2 = MLP(64, 128)\n",
        "        self.mlp3 = MLP(128, 1024)\n",
        "\n",
        "        self.fc_bn1 = FC_BN(1024, 512)\n",
        "        self.fc_bn2 = FC_BN(512,256)\n",
        "\n",
        "        self.fc3 = nn.Linear(256,k*k)\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        # input.shape == (batch_size,n,3)\n",
        "\n",
        "        bs = input.size(0)\n",
        "        xb = self.mlp1(input)\n",
        "        xb = self.mlp2(xb)\n",
        "        xb = self.mlp3(xb)\n",
        "\n",
        "        pool = nn.MaxPool1d(xb.size(-1))(xb)\n",
        "        flat = nn.Flatten(1)(pool)\n",
        "\n",
        "        xb = self.fc_bn1(flat)\n",
        "        xb = self.fc_bn2(xb)\n",
        "\n",
        "        #initialize as identity\n",
        "        init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n",
        "        if xb.is_cuda:\n",
        "            init=init.cuda()\n",
        "        matrix = self.fc3(xb).view(-1,self.k,self.k) + init\n",
        "        return matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "mEQ4Zx5WoLDx",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class TinyPointNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.input_transform   = TNet(k=3) ## if you use the shot rotation matrix, this is not going to be used\n",
        "        self.feature_transform = TNet(k=64)\n",
        "\n",
        "        ############# START ###########\n",
        "        ######### COMPLETE HERE #######\n",
        "        self.mlp1 = MLP(3, 64)  # Input size is 3 (x, y, z) and output size is 64\n",
        "        self.mlp2 = MLP(64, 128)\n",
        "        self.mlp3 = MLP(128, 1024)\n",
        "\n",
        "        self.fc_bn1 = FC_BN(1024, 512)\n",
        "        self.fc_bn2 = FC_BN(512, 256)\n",
        "        self.fc_bn3 = FC_BN(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 256)  # final output size, 256 for example\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "\n",
        "        ############# END #############\n",
        "\n",
        "    def forward(self, input):\n",
        "        n_pts = input.size()[2]\n",
        "        # matrix3x3 = self.input_transform(input)\n",
        "        matrix3x3 = self.shot_canonical_rotation(input, 3)\n",
        "        input_transform_output = torch.bmm(torch.transpose(input,1,2), matrix3x3).transpose(1,2)\n",
        "\n",
        "\n",
        "        ############# START ###########\n",
        "        ######### COMPLETE HERE #######\n",
        "        x = self.mlp1(input_transform_output)\n",
        "        x = self.mlp2(x)\n",
        "        x = self.mlp3(x)\n",
        "\n",
        "        x = torch.max(x, 2, keepdim=True)[0]\n",
        "        x = x.view(-1, 1024)\n",
        "\n",
        "        x = self.fc_bn1(x)\n",
        "        x = self.fc_bn2(x)\n",
        "        x = self.fc_bn3(x)\n",
        "        x = self.dropout(x)\n",
        "        global_feature = self.fc4(x)\n",
        "\n",
        "        ############# END #############\n",
        "\n",
        "        return global_feature\n",
        "\n",
        "    def shot_canonical_rotation(self, input, k):\n",
        "        # input.shape == (batch_size, n, k)\n",
        "        batch_size, n, _ = input.size()\n",
        "        rotation_matrices = []\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            features_batch = input[i]\n",
        "            centroid = torch.mean(features_batch, dim=1, keepdim=True)\n",
        "            centered_features = features_batch - centroid\n",
        "\n",
        "            if torch.any(torch.isnan(centered_features)) or torch.any(torch.isinf(centered_features)):\n",
        "                centered_features[torch.isnan(centered_features) | torch.isinf(centered_features)] = 1e-6\n",
        "\n",
        "            distances = torch.norm(centered_features, dim=0)\n",
        "\n",
        "            weights = 1.0 - distances\n",
        "            weights[weights < 0] = 0\n",
        "\n",
        "            weights_sum = torch.sum(weights)\n",
        "            if weights_sum > 0:\n",
        "                weights = weights / weights_sum\n",
        "            else:\n",
        "                weights = torch.ones_like(weights) / n\n",
        "\n",
        "            weighted_cov_matrix = torch.zeros((centered_features.size(0), centered_features.size(0)), device=input.device)\n",
        "\n",
        "            ############# START ###########\n",
        "            ######### COMPLETE HERE #######\n",
        "            ### compute the covariance matrix\n",
        "            for j in range(n):\n",
        "              weighted_cov_matrix += weights[j] * torch.ger(centered_features[:, j], centered_features[:, j])\n",
        "\n",
        "            ############# END #############\n",
        "\n",
        "            weighted_cov_matrix += torch.eye(weighted_cov_matrix.size(-1), device=input.device) * 1e-6\n",
        "\n",
        "            ############# START ###########\n",
        "            ######### COMPLETE HERE #######\n",
        "            ### compute the eigenvectors of covariance matrix\n",
        "            _, V = torch.symeig(weighted_cov_matrix, eigenvectors=True)\n",
        "\n",
        "            ############# END #############\n",
        "\n",
        "            rotation_matrix = V[:, :k]\n",
        "\n",
        "            for j in range(k):\n",
        "                signs = torch.sign(torch.sum(centered_features * rotation_matrix[:, j].unsqueeze(1), dim=0))\n",
        "                if torch.sum(signs >= 0) < torch.sum(signs < 0):\n",
        "                    rotation_matrix[:, j] = -rotation_matrix[:, j]\n",
        "\n",
        "            rotation_matrices.append(rotation_matrix)\n",
        "\n",
        "        return torch.stack(rotation_matrices, dim=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P38WBTtMyFeC",
        "tags": []
      },
      "source": [
        "# Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "vIlTUpNPyBdK",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a5ee2e8-c4e1-4848-f92e-37141e3f28b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "uWSroT5TyDnt",
        "tags": []
      },
      "outputs": [],
      "source": [
        "tinypointnet = TinyPointNet()\n",
        "tinypointnet.to(device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "wqwUjESLyKv3",
        "tags": []
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(tinypointnet.parameters(), lr=0.0005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "CAf8UGcPazjx",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from torch.nn import TripletMarginLoss\n",
        "\n",
        "def train(model, train_loader, valid_loader=None,  epochs=45, save=True):\n",
        "    best_valid_loss = 1e10\n",
        "    ############## START #############\n",
        "    ####### COMPLETE THIS PART: put the correct loss function #######\n",
        "    # tinypointnetloss =\n",
        "    tinypointnetloss = TripletMarginLoss(margin=1.0, p=2)\n",
        "    ############## END ###############\n",
        "\n",
        "    # these lists keep track of the losses across epochs\n",
        "    train_losses, valid_losses = [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # local list of losses\n",
        "        train_loss, valid_loss = [], []\n",
        "\n",
        "        # train\n",
        "        tinypointnet.train()\n",
        "\n",
        "        for (_, anchor, positive, negative, _, _, _, _) in tqdm(train_loader):\n",
        "\n",
        "            # retrieve anchors, positives and negatives batch\n",
        "            anchor   =   anchor.to(device).float().transpose(1,2)\n",
        "            positive = positive.to(device).float().transpose(1,2)\n",
        "            negative = negative.to(device).float().transpose(1,2)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # let PointNetTiny model compute the descriptors\n",
        "            anchor_desc   = tinypointnet(anchor)\n",
        "            positive_desc = tinypointnet(positive)\n",
        "            negative_desc = tinypointnet(negative)\n",
        "\n",
        "            # compute the loss associated to these descriptors\n",
        "            loss = tinypointnetloss(anchor_desc, positive_desc, negative_desc)\n",
        "\n",
        "            # Backpropagate the gradient\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Keep track of the statistics\n",
        "            train_loss.append(loss.item())\n",
        "            #pbar.set_postfix(loss=curr_loss)\n",
        "\n",
        "        train_loss = np.asarray(train_loss).mean()\n",
        "        print(f'epoch {epoch} - train loss:', train_loss)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # validation\n",
        "        tinypointnet.eval()\n",
        "        pbar = tqdm(valid_loader, leave=False)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for (_, anchor, positive, negative, _, _, _, _) in pbar:\n",
        "                pbar.set_description(f\"valid - epoch {epoch}\")\n",
        "\n",
        "                anchor   =   anchor.to(device).float().transpose(1,2)\n",
        "                positive = positive.to(device).float().transpose(1,2)\n",
        "                negative = negative.to(device).float().transpose(1,2)\n",
        "\n",
        "                anchor_desc   = tinypointnet(anchor)\n",
        "                positive_desc = tinypointnet(positive)\n",
        "                negative_desc = tinypointnet(negative)\n",
        "                loss = tinypointnetloss(anchor_desc, positive_desc, negative_desc)\n",
        "                curr_loss = loss.item()\n",
        "\n",
        "                valid_loss.append(curr_loss)\n",
        "\n",
        "                pbar.set_postfix(loss=curr_loss)\n",
        "\n",
        "        valid_loss = np.asarray(valid_loss).mean()\n",
        "        print(f'epoch {epoch} - valid loss:', valid_loss)\n",
        "        valid_losses.append(valid_loss)\n",
        "\n",
        "        # save the model\n",
        "        if save and valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            if running_on_colab:\n",
        "                path = os.path.join(drive_path, \"MyDrive\", \"tinypointnetmodel.yml\")\n",
        "            else:\n",
        "                path = os.path.join(\"tinypointnetmodel.yml\")\n",
        "            print(\"best_valid_loss:\", best_valid_loss, \"saving model at\", path)\n",
        "            torch.save(tinypointnet.state_dict(), path)\n",
        "    return train_losses, valid_losses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "pCioSo6kyU5M",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "a0f6e50a-69eb-4e19-88ee-d0d9a963a4ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "high <= 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-9d47485c347b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtinypointnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-38-9c5674f2c13e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, valid_loader, epochs, save)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtinypointnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# retrieve anchors, positives and negatives batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-4f290661f0f2>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, _)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mmesh_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mpcd_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpcds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmesh_idx\u001b[0m\u001b[0;34m]\u001b[0m        \u001b[0;31m## anchor will be drawn from this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_bounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: high <= 0"
          ]
        }
      ],
      "source": [
        "train_losses, valid_losses = train(tinypointnet, train_loader, valid_loader, save=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxxvdXzn10u5"
      },
      "source": [
        "## Visualize the Training trend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22ECIGIZ10u6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def numpy_ewma_vectorized_v2(data, window=10):\n",
        "    # Return the Exponentially Weighted Moving Average\n",
        "    # for better visualizing the \"trend\" of the metrics\n",
        "\n",
        "    alpha = 2 /(window + 1.0)\n",
        "    alpha_rev = 1-alpha\n",
        "    n = data.shape[0]\n",
        "\n",
        "    pows = alpha_rev**(np.arange(n+1))\n",
        "\n",
        "    scale_arr = 1/pows[:-1]\n",
        "    offset = data[0]*pows[1:]\n",
        "    pw0 = alpha*alpha_rev**(n-1)\n",
        "\n",
        "    mult = data*pw0*scale_arr\n",
        "    cumsums = mult.cumsum()\n",
        "    out = offset + cumsums*scale_arr[::-1]\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2PDOXU710u6"
      },
      "source": [
        "### Plot the trend of train and valid losses\n",
        "By using an Exponentially Weighted Moving Average of the losses,\n",
        "we can better understand the behaviour of our network by filtering out\n",
        "the noisy *local values* and focusing more on the *global trend*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PIDERVU10u6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "plt.plot(train_losses, label=\"train losses\", color='r', alpha=0.2)\n",
        "plt.plot(valid_losses, label=\"valid losses\", color='b', alpha=0.2)\n",
        "plt.plot(numpy_ewma_vectorized_v2(np.array(train_losses)), label=\"train losses EMA\", color='r')\n",
        "plt.plot(numpy_ewma_vectorized_v2(np.array(valid_losses)), label=\"valid losses EMA\", color='b')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irrVJH1UJb92",
        "tags": []
      },
      "source": [
        "# Test: feature matching\n",
        "\n",
        "Let's compute the model test metrics\n",
        "\n",
        "> First we need to load the best model weights\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "4-zerKDe5ehO"
      },
      "source": [
        "## Load checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IqRQrxg10u6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "if running_on_colab:\n",
        "    path = os.path.join(drive_path, \"MyDrive\", \"tinypointnetmodel.yml\")\n",
        "else:\n",
        "    path = os.path.join(\"tinypointnetmodel.yml\")\n",
        "tinypointnet = TinyPointNet()\n",
        "tinypointnet.load_state_dict(torch.load(path))\n",
        "tinypointnet.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "8m8rItsr5ehP"
      },
      "source": [
        "## Prepare the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PI4YkY6Od2PH",
        "tags": []
      },
      "outputs": [],
      "source": [
        "test_ds.generate_test_set(0, 2000)\n",
        "\n",
        "## build the ground truth nearest neighbors\n",
        "## in other words, find thepoints in the noisy test points\n",
        "## that are the nearest neighbors to the original, sampled, test points\n",
        "test_ds.generate_noisy_test_set(0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0MIIG0G5ehR"
      },
      "source": [
        "### Visualize the sampled test points\n",
        "Little red spheres represent the test points sampled from the original test mesh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "omL51h7d5ehS"
      },
      "outputs": [],
      "source": [
        "pcd = o3d.geometry.PointCloud()\n",
        "pcd.points = o3d.utility.Vector3dVector(test_ds.test_points_sampled_n)\n",
        "pcd.paint_uniform_color([0.5, 0.5, 0.5])\n",
        "geoms = [pcd]\n",
        "\n",
        "# visualize the colored point cloud\n",
        "o3d.visualization.draw_geometries(geoms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "IYjTYoCG5ehh"
      },
      "outputs": [],
      "source": [
        "pcd = test_ds.get_sampled_pointcloud(mesh_idx=0, N=5000)\n",
        "pcd.paint_uniform_color([0.5, 0.5, 0.5])\n",
        "geoms = [pcd]\n",
        "for point in test_ds.test_points_sampled_n:\n",
        "    sphere = o3d.geometry.TriangleMesh.create_sphere(radius=1e-3)\n",
        "    sphere.translate(point)\n",
        "    sphere.paint_uniform_color([1, 0, 0])\n",
        "    geoms.append(sphere)\n",
        "\n",
        "# visualize the colored point cloud\n",
        "o3d.visualization.draw_geometries(geoms)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n892Mu465ehi"
      },
      "source": [
        "### Compute the descriptor of each point in each point set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3jBS-ev10u6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "descs   = test_ds.compute_descriptors(tinypointnet)\n",
        "descs_n = test_ds.compute_descriptors(tinypointnet, noisy=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7lGJGuz5ehj"
      },
      "source": [
        "## matching time!\n",
        "In other words, get the descriptor from the noisy point cloud which is closest to the query descriptor from the original point cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "VmF9vobF5ehj"
      },
      "outputs": [],
      "source": [
        "pcd = test_ds.get_sampled_pointcloud(mesh_idx=0, N=5000)\n",
        "pcd.paint_uniform_color([0.5, 0.5, 0.5])\n",
        "geoms = [pcd]\n",
        "for row in tqdm(range(test_ds.test_points_sampled_n.shape[0])):\n",
        "    anchor       = test_ds.test_points_sampled[row]\n",
        "    sphere = o3d.geometry.TriangleMesh.create_sphere(radius=1e-3)\n",
        "    sphere.translate(anchor)\n",
        "    sphere.paint_uniform_color([1, 0, 0])\n",
        "    geoms.append(sphere)\n",
        "\n",
        "\n",
        "o3d.visualization.draw_geometries(geoms)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "pNfCB-9V5ehj"
      },
      "outputs": [],
      "source": [
        "correct = tot = 0\n",
        "\n",
        "for row in tqdm(range(test_ds.test_points_sampled.shape[0])):\n",
        "    desc = descs[row, :]\n",
        "    dists = []\n",
        "    anchor       = test_ds.test_points_sampled[row]\n",
        "    true_near_pt = test_ds.test_points_sampled_n[row]\n",
        "\n",
        "    for row2 in range(test_ds.test_points_sampled_n.shape[0]):\n",
        "        desc2 = descs_n[row2, :]\n",
        "        dist = np.linalg.norm(desc - desc2)\n",
        "        dists.append(dist)\n",
        "\n",
        "    min_row = np.argmin(np.asarray(dists))\n",
        "\n",
        "    pred_pt = test_ds.test_points_sampled_n[min_row].squeeze()\n",
        "\n",
        "    dist = np.linalg.norm(true_near_pt - pred_pt)\n",
        "\n",
        "    # visualize(test_ds.test_points_sampled,\n",
        "    #           anchor = anchor,\n",
        "    #           positive = pred_pt,\n",
        "    #           radius=test_ds.radius)\n",
        "\n",
        "    if dist<test_ds.radius:\n",
        "        correct += 1\n",
        "    tot += 1\n",
        "\n",
        "print()\n",
        "print(f\"accuracy: {correct*100/tot:6.3f}%\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "venv111",
      "language": "python",
      "name": "venv111"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}